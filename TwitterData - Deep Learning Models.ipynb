{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.14 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pyarrow) (1.18.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Need this to read parquet file format into pandas dataframe\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (0.7.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from imbalanced-learn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from imbalanced-learn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from imbalanced-learn) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from imbalanced-learn) (0.23.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-learn>=0.23->imbalanced-learn) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import tensorflow as tf\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "#from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 17037567901941032771,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 10537375238087818236\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 13540715296108806658\n",
       " physical_device_desc: \"device: XLA_GPU device\",\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11338085172\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 10512267807107589793\n",
       " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the labeled data into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the labeled data into the pandas dataframe\n",
    "part0 = 's3://bauka-big-tweets/tweets_2class.parquet/part-00000-0b07c410-f74a-444d-b425-a1e1bbcb1684-c000.snappy.parquet'\n",
    "part1 = 's3://bauka-big-tweets/tweets_2class.parquet/part-00001-0b07c410-f74a-444d-b425-a1e1bbcb1684-c000.snappy.parquet'\n",
    "part2 = 's3://bauka-big-tweets/tweets_2class.parquet/part-00002-0b07c410-f74a-444d-b425-a1e1bbcb1684-c000.snappy.parquet'\n",
    "part3 = 's3://bauka-big-tweets/tweets_2class.parquet/part-00003-0b07c410-f74a-444d-b425-a1e1bbcb1684-c000.snappy.parquet'\n",
    "part4 = 's3://bauka-big-tweets/tweets_2class.parquet/part-00004-0b07c410-f74a-444d-b425-a1e1bbcb1684-c000.snappy.parquet'\n",
    "part5 = 's3://bauka-big-tweets/tweets_2class.parquet/part-00005-0b07c410-f74a-444d-b425-a1e1bbcb1684-c000.snappy.parquet'\n",
    "part6 = 's3://bauka-big-tweets/tweets_2class.parquet/part-00006-0b07c410-f74a-444d-b425-a1e1bbcb1684-c000.snappy.parquet'\n",
    "part7 = 's3://bauka-big-tweets/tweets_2class.parquet/part-00007-0b07c410-f74a-444d-b425-a1e1bbcb1684-c000.snappy.parquet'\n",
    "data0 = pd.read_parquet(part0, engine='pyarrow')\n",
    "data1 = pd.read_parquet(part1, engine='pyarrow')\n",
    "data2 = pd.read_parquet(part2, engine='pyarrow')\n",
    "data3 = pd.read_parquet(part3, engine='pyarrow')\n",
    "data4 = pd.read_parquet(part4, engine='pyarrow')\n",
    "data5 = pd.read_parquet(part5, engine='pyarrow')\n",
    "data6 = pd.read_parquet(part6, engine='pyarrow')\n",
    "data7 = pd.read_parquet(part7, engine='pyarrow')\n",
    "labeled_data = pd.concat([data0, data1, data2, data3, data4, data5, data6, data7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the tidy (lemmatized) data into pandas dataframe\n",
    "client = boto3.client('s3')\n",
    "path = 's3://bauka-big-tweets/lemmatized.json'\n",
    "df= pd.read_json(path, orient='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = df['tokens_back_to_text']\n",
    "type(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 65125 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = len(word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labeled_data['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    407662\n",
       "1       104\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE - balance the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "# define pipeline\n",
    "over = SMOTE(sampling_strategy=0.3)\n",
    "under = RandomUnderSampler(sampling_strategy=0.8)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "X, y = pipeline.fit_resample(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 152872, 1: 122298})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding of labels\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((275170, 12), (275170, 2))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data set first\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=43, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137585, 12), (137585, 12), (137585, 2), (137585, 2))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling - deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleRNN\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = max_features, output_dim = 100, input_length = maxlen))\n",
    "model.add(SimpleRNN(output_dim=100, return_sequences=True))\n",
    "model.add(SimpleRNN(output_dim=100, return_sequences=True))\n",
    "model.add(SimpleRNN(output_dim=100, return_sequences=True))\n",
    "model.add(SimpleRNN(output_dim=100))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='rmsprop', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55034 samples, validate on 82551 samples\n",
      "Epoch 1/3\n",
      "55034/55034 [==============================] - 125s 2ms/step - loss: 0.0038 - acc: 0.9989 - val_loss: 1.0961e-07 - val_acc: 1.0000\n",
      "Epoch 2/3\n",
      "55034/55034 [==============================] - 123s 2ms/step - loss: 1.0961e-07 - acc: 1.0000 - val_loss: 1.0961e-07 - val_acc: 1.0000\n",
      "Epoch 3/3\n",
      "55034/55034 [==============================] - 122s 2ms/step - loss: 1.0960e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training set\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model.fit(X_train, y_train, epochs=3, validation_split=0.6)\n",
    "# Final evaluation of the model\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = max_features, output_dim = 100, input_length = maxlen))\n",
    "model.add(LSTM(output_dim=100))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='rmsprop', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96309 samples, validate on 41276 samples\n",
      "Epoch 1/3\n",
      "96309/96309 [==============================] - 104s 1ms/step - loss: 0.0032 - acc: 0.9997 - val_loss: 1.1535e-07 - val_acc: 1.0000\n",
      "Epoch 2/3\n",
      "96309/96309 [==============================] - 100s 1ms/step - loss: 1.0960e-07 - acc: 1.0000 - val_loss: 1.1535e-07 - val_acc: 1.0000\n",
      "Epoch 3/3\n",
      "96309/96309 [==============================] - 103s 1ms/step - loss: 1.0960e-07 - acc: 1.0000 - val_loss: 1.1535e-07 - val_acc: 1.0000\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training set\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model.fit(X_train, y_train, epochs=3, validation_split=0.3)\n",
    "# Final evaluation of the model\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov  3 20:38:38 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   49C    P0    57W / 149W |  10963MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      9335      C   ...tensorflow_p36/bin/python    10958MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
