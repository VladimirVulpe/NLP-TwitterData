{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "What are the main opinions observed from the tweets related to the 2020 US election? What are people talking about on Twitter two weeks prior to election day?\n",
    "\n",
    "### Context\n",
    "\n",
    "October surprise, according to Wikipedia, is a U.S. political jargon and a news event that may influence the outcome of an upcoming November election, particularly one for the U.S. presidency), whether deliberately planned or spontaneously occurring. Tweeter is a great source of unfiltered conversations, opinions and news events directly posted by the individuals themselves compared to the filtered news provided by the media outlets. This project analyses various sentiments from the tweets occurring 2 weeks prior to the election day to identify main topics people are talking about and October surprises. \n",
    "\n",
    "### Criteria For Success\n",
    "\n",
    "Achieve at least 75% accuracy in predicting the topics of the tweets.\n",
    "\n",
    "### Scope of Solution Space\n",
    "\n",
    "Solution scope will be limited to analysing the tweets related to the 2020 US election. In the modeling section, the main focus will be given to the training and evaluating deep learning models with the text data. While labeling of the tweets is required as part of the project, it is out of the scope of the project to improve the performance of the labeling job. \n",
    "\n",
    "### Solution Approach\n",
    "* Collect data from the Twitter with the relevant keywords\n",
    "* Apply Natural Language Processing (NLP) techniques to clean and preprocess the data\n",
    "* Distributed computing will be used to preprocess and label the data set\n",
    "* Train and evaluate SimpleRNN and LSTM models in Keras\n",
    "\n",
    "### Constraints\n",
    "\n",
    "* Limitation of computational power/resource\n",
    "* Limited hands-on experience in advanced deep learning techniques\n",
    "* Access to the distributed computing platforms and technical challenges\n",
    "\n",
    "### Stakeholders\n",
    "\n",
    "The report will be intended for and will be shared with the general public\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "* Final Report\n",
    "* Final Presentation\n",
    "* Jupyter notebooks with the code for each stage of the data science method\n",
    "* Model deployment into production\n",
    "* Article on Medium / TDS\n",
    "\n",
    "### Data Sources\n",
    "Data will be collected directly from the Twitter social media platform via the Twitter API and Tweepy package in Python. The data set will contain over 440,000 raw tweets about the 2020 US election from over 2 weeks prior to the election day.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection - Streaming Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading tweepy-3.9.0-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tweepy) (1.14.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tweepy) (2.22.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests[socks]>=2.11.1->tweepy) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests[socks]>=2.11.1->tweepy) (2020.6.20)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests[socks]>=2.11.1->tweepy) (2.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 10.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-3.1.0 requests-oauthlib-1.3.0 tweepy-3.9.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install Tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API consumer keys\n",
    "access_token = \"  insert your here  \"\n",
    "access_token_secret = \"  insert your here  \"\n",
    "consumer_key = \"  insert your here  \"\n",
    "consumer_secret = \"  insert your here  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API authorization\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    \"\"\"Function to listen and stream Twitter data\"\"\"\n",
    "    def __init__(self, api=None):\n",
    "        super(MyStreamListener, self).__init__()\n",
    "        self.num_tweets = 0\n",
    "        self.file = open(\"tweets.txt\", \"w\")\n",
    "\n",
    "    def on_status(self, status):\n",
    "        tweet = status._json\n",
    "        self.file.write( json.dumps(tweet) + '\\n' )\n",
    "        self.num_tweets += 1\n",
    "        if self.num_tweets < 20000:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        self.file.close()\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Determine your data collection apporach  \n",
    "I stream and collect Twitter data in 11 chunks due to its computational intensity and I run through these 11 chunks twice to ultimately collect 500,000 tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Let the stream being!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener = MyStreamListener()\n",
    "stream = tweepy.Stream(auth, listener)\n",
    "stream.filter(track = ['US Election', 'election', 'trump', 'Mike Pence', 'biden', 'Kamala Harris', 'Donald Trump', 'Joe Biden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['created_at', 'id', 'id_str', 'text', 'display_text_range', 'source', 'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'is_quote_status', 'extended_tweet', 'quote_count', 'reply_count', 'retweet_count', 'favorite_count', 'entities', 'favorited', 'retweeted', 'filter_level', 'lang', 'timestamp_ms'])\n"
     ]
    }
   ],
   "source": [
    "tweets_data_path = 'tweets.txt'\n",
    "tweets_data=[]\n",
    "tweets_file_1 = open(tweets_data_path, 'r')\n",
    "# Read in tweets and store in list: tweets_data\n",
    "for line in tweets_file_1:\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# Close connection to file\n",
    "tweets_file_1.close()\n",
    "\n",
    "# Print the keys of the first tweet dict\n",
    "print(tweets_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['created_at', 'id', 'id_str', 'text', 'source', 'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str', \\\n",
    "         'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', \\\n",
    "         'contributors', 'retweeted_status', 'quoted_status_id', 'quoted_status_id_str', 'quoted_status', \\\n",
    "         'quoted_status_permalink', 'is_quote_status', 'quote_count', 'reply_count', 'retweet_count', 'favorite_count', \\\n",
    "         'entities', 'favorited', 'retweeted', 'filter_level', 'lang', 'timestamp_ms']\n",
    "df1 = pd.DataFrame(tweets_data, columns= names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19999, 32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener = MyStreamListener()\n",
    "stream = tweepy.Stream(auth, listener)\n",
    "stream.filter(track = ['US Election', 'Election', 'Trump', 'pence', 'biden', 'harris', 'Donald Trump', 'Joe Biden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['created_at', 'id', 'id_str', 'text', 'source', 'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'retweeted_status', 'is_quote_status', 'quote_count', 'reply_count', 'retweet_count', 'favorite_count', 'entities', 'favorited', 'retweeted', 'filter_level', 'lang', 'timestamp_ms'])\n"
     ]
    }
   ],
   "source": [
    "tweets_data_path = 'tweets.txt'\n",
    "tweets_data=[]\n",
    "tweets_file_2 = open(tweets_data_path, 'r')\n",
    "# Read in tweets and store in list: tweets_data\n",
    "for line in tweets_file_2:\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# Close connection to file\n",
    "tweets_file_2.close()\n",
    "\n",
    "# Print the keys of the first tweet dict\n",
    "print(tweets_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd Streaming\n",
    "df2 = pd.DataFrame(tweets_data, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener = MyStreamListener()\n",
    "stream = tweepy.Stream(auth, listener)\n",
    "stream.filter(track = ['US Election', 'Election', 'Trump', 'Pence', 'Biden', 'Harris', 'Donald Trump', 'Sleepy Joe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['created_at', 'id', 'id_str', 'text', 'display_text_range', 'source', 'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'quoted_status_id', 'quoted_status_id_str', 'quoted_status', 'quoted_status_permalink', 'is_quote_status', 'quote_count', 'reply_count', 'retweet_count', 'favorite_count', 'entities', 'extended_entities', 'favorited', 'retweeted', 'possibly_sensitive', 'filter_level', 'lang', 'timestamp_ms'])\n"
     ]
    }
   ],
   "source": [
    "tweets_data_path = 'tweets.txt'\n",
    "tweets_data=[]\n",
    "tweets_file_3 = open(tweets_data_path, 'r')\n",
    "# Read in tweets and store in list: tweets_data\n",
    "for line in tweets_file_3:\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# Close connection to file\n",
    "tweets_file_3.close()\n",
    "\n",
    "# Print the keys of the first tweet dict\n",
    "print(tweets_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd Streaming\n",
    "df3 = pd.DataFrame(tweets_data, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener = MyStreamListener()\n",
    "stream = tweepy.Stream(auth, listener)\n",
    "stream.filter(track = ['2021 Presidential Election', 'election', 'trump', 'pence', 'biden', 'harris', 'Donald Trump', 'Joe Biden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['created_at', 'id', 'id_str', 'text', 'display_text_range', 'source', 'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'is_quote_status', 'quote_count', 'reply_count', 'retweet_count', 'favorite_count', 'entities', 'favorited', 'retweeted', 'filter_level', 'lang', 'timestamp_ms'])\n"
     ]
    }
   ],
   "source": [
    "tweets_data_path = 'tweets.txt'\n",
    "tweets_data=[]\n",
    "tweets_file_4 = open(tweets_data_path, 'r')\n",
    "# Read in tweets and store in list: tweets_data\n",
    "for line in tweets_file_4:\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# Close connection to file\n",
    "tweets_file_4.close()\n",
    "\n",
    "# Print the keys of the first tweet dict\n",
    "print(tweets_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4th Streaming\n",
    "df4 = pd.DataFrame(tweets_data, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener = MyStreamListener()\n",
    "stream = tweepy.Stream(auth, listener)\n",
    "stream.filter(track = ['US COVID19', 'Covid', 'covid19', 'election', 'trump', 'pence', 'biden', 'harris', 'Donald Trump', 'Joe Biden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['created_at', 'id', 'id_str', 'text', 'source', 'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'retweeted_status', 'is_quote_status', 'quote_count', 'reply_count', 'retweet_count', 'favorite_count', 'entities', 'favorited', 'retweeted', 'filter_level', 'lang', 'timestamp_ms'])\n"
     ]
    }
   ],
   "source": [
    "tweets_data_path = 'tweets.txt'\n",
    "tweets_data=[]\n",
    "tweets_file_5 = open(tweets_data_path, 'r')\n",
    "# Read in tweets and store in list: tweets_data\n",
    "for line in tweets_file_5:\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# Close connection to file\n",
    "tweets_file_5.close()\n",
    "\n",
    "# Print the keys of the first tweet dict\n",
    "print(tweets_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = pd.DataFrame(tweets_data, columns=names)\n",
    "df5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener = MyStreamListener()\n",
    "stream = tweepy.Stream(auth, listener)\n",
    "stream.filter(track = ['USA COVID19', 'US Covid', 'usa covid-19', 'usa election', 'Trump', 'Pence', 'Biden', 'Harris'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['created_at', 'id', 'id_str', 'text', 'source', 'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'retweeted_status', 'is_quote_status', 'quote_count', 'reply_count', 'retweet_count', 'favorite_count', 'entities', 'extended_entities', 'favorited', 'retweeted', 'possibly_sensitive', 'filter_level', 'lang', 'timestamp_ms'])\n"
     ]
    }
   ],
   "source": [
    "tweets_data_path = 'tweets.txt'\n",
    "tweets_data=[]\n",
    "tweets_file_6 = open(tweets_data_path, 'r')\n",
    "# Read in tweets and store in list: tweets_data\n",
    "for line in tweets_file_6:\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# Close connection to file\n",
    "tweets_file_6.close()\n",
    "\n",
    "# Print the keys of the first tweet dict\n",
    "print(tweets_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.DataFrame(tweets_data, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener = MyStreamListener()\n",
    "stream = tweepy.Stream(auth, listener)\n",
    "stream.filter(track = ['GOP', 'Democrats', 'usa covid-19', 'usa election', 'Trump', 'Pence', 'Biden', 'Harris', 'COVID19'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['created_at', 'id', 'id_str', 'text', 'source', 'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'retweeted_status', 'is_quote_status', 'quote_count', 'reply_count', 'retweet_count', 'favorite_count', 'entities', 'favorited', 'retweeted', 'filter_level', 'lang', 'timestamp_ms'])\n"
     ]
    }
   ],
   "source": [
    "tweets_data_path = 'tweets.txt'\n",
    "tweets_data=[]\n",
    "tweets_file_7 = open(tweets_data_path, 'r')\n",
    "# Read in tweets and store in list: tweets_data\n",
    "for line in tweets_file_7:\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# Close connection to file\n",
    "tweets_file_7.close()\n",
    "\n",
    "# Print the keys of the first tweet dict\n",
    "print(tweets_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = pd.DataFrame(tweets_data, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener = MyStreamListener()\n",
    "stream = tweepy.Stream(auth, listener)\n",
    "stream.filter(track = ['US', 'China', 'Democrats', 'Republicans', 'usa election', 'Trump', 'Pence', 'Biden', 'Harris', 'COVID19'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['created_at', 'id', 'id_str', 'text', 'source', 'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'retweeted_status', 'is_quote_status', 'quote_count', 'reply_count', 'retweet_count', 'favorite_count', 'entities', 'favorited', 'retweeted', 'possibly_sensitive', 'filter_level', 'lang', 'timestamp_ms'])\n"
     ]
    }
   ],
   "source": [
    "tweets_data_path = 'tweets.txt'\n",
    "tweets_data=[]\n",
    "tweets_file_8 = open(tweets_data_path, 'r')\n",
    "# Read in tweets and store in list: tweets_data\n",
    "for line in tweets_file_8:\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# Close connection to file\n",
    "tweets_file_8.close()\n",
    "\n",
    "# Print the keys of the first tweet dict\n",
    "print(tweets_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = pd.DataFrame(tweets_data, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19999, 32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener = MyStreamListener()\n",
    "stream = tweepy.Stream(auth, listener)\n",
    "stream.filter(track = ['election', 'Democrats', 'Republicans', 'election', 'Trump', 'Pence', 'Biden', 'Harris', 'US Election'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['created_at', 'id', 'id_str', 'text', 'source', 'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'retweeted_status', 'is_quote_status', 'quote_count', 'reply_count', 'retweet_count', 'favorite_count', 'entities', 'favorited', 'retweeted', 'filter_level', 'lang', 'timestamp_ms'])\n"
     ]
    }
   ],
   "source": [
    "tweets_data_path = 'tweets.txt'\n",
    "tweets_data=[]\n",
    "tweets_file_9 = open(tweets_data_path, 'r')\n",
    "# Read in tweets and store in list: tweets_data\n",
    "for line in tweets_file_9:\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# Close connection to file\n",
    "tweets_file_9.close()\n",
    "\n",
    "# Print the keys of the first tweet dict\n",
    "print(tweets_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = pd.DataFrame(tweets_data, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener = MyStreamListener()\n",
    "stream = tweepy.Stream(auth, listener)\n",
    "stream.filter(track = ['Democrats', 'US Congress', 'BLM', 'Republicans', 'election', 'Trump', 'Pence', 'Biden', 'Harris', 'US Election'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['created_at', 'id', 'id_str', 'text', 'source', 'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'retweeted_status', 'quoted_status_id', 'quoted_status_id_str', 'quoted_status', 'quoted_status_permalink', 'is_quote_status', 'quote_count', 'reply_count', 'retweet_count', 'favorite_count', 'entities', 'favorited', 'retweeted', 'filter_level', 'lang', 'timestamp_ms'])\n"
     ]
    }
   ],
   "source": [
    "tweets_data_path = 'tweets.txt'\n",
    "tweets_data=[]\n",
    "tweets_file_10 = open(tweets_data_path, 'r')\n",
    "# Read in tweets and store in list: tweets_data\n",
    "for line in tweets_file_10:\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# Close connection to file\n",
    "tweets_file_10.close()\n",
    "\n",
    "# Print the keys of the first tweet dict\n",
    "print(tweets_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = pd.DataFrame(tweets_data, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19998, 32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener = MyStreamListener()\n",
    "stream = tweepy.Stream(auth, listener)\n",
    "stream.filter(track = ['Republicans', 'election', 'Democrats', 'Donald Trump', 'Pence', 'Joe Biden', 'Harris', 'usa election'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['created_at', 'id', 'id_str', 'text', 'source', 'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'quoted_status_id', 'quoted_status_id_str', 'quoted_status', 'quoted_status_permalink', 'is_quote_status', 'quote_count', 'reply_count', 'retweet_count', 'favorite_count', 'entities', 'favorited', 'retweeted', 'filter_level', 'lang', 'timestamp_ms'])\n"
     ]
    }
   ],
   "source": [
    "tweets_data_path = 'tweets.txt'\n",
    "tweets_data=[]\n",
    "tweets_file_11 = open(tweets_data_path, 'r')\n",
    "# Read in tweets and store in list: tweets_data\n",
    "for line in tweets_file_11:\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# Close connection to file\n",
    "tweets_file_11.close()\n",
    "\n",
    "# Print the keys of the first tweet dict\n",
    "print(tweets_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = pd.DataFrame(tweets_data, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19999, 32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df11.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Combine All Data Chunks Into A Single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219995, 32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Save the combined data in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tweets_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Step: Combine the CSV files into a single data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (1,2,5,8,12,13,18,21,23,24,25,27,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "first_run = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220004, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_run.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (12,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "second_run = pd.read_csv('tweets_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219995, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_run.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(439999, 32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = pd.concat([first_run, second_run], ignore_index=True)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>entities</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>filter_level</th>\n",
       "      <th>lang</th>\n",
       "      <th>timestamp_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Oct 16 05:01:51 +0000 2020</td>\n",
       "      <td>1316967569660776450</td>\n",
       "      <td>1316967569660776450</td>\n",
       "      <td>RT @RudyGiuliani: The competing Town Halls wer...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>1.602825e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Oct 16 05:01:51 +0000 2020</td>\n",
       "      <td>1316967569648222211</td>\n",
       "      <td>1316967569648222211</td>\n",
       "      <td>RT @rachelv12: Trump and machismo  https://t.c...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>1.602825e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Oct 16 05:01:51 +0000 2020</td>\n",
       "      <td>1316967569652371456</td>\n",
       "      <td>1316967569652371456</td>\n",
       "      <td>RT @briantylercohen: Biden is like an encyclop...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>1.602825e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri Oct 16 05:01:51 +0000 2020</td>\n",
       "      <td>1316967569652371458</td>\n",
       "      <td>1316967569652371458</td>\n",
       "      <td>RT @BradleyWhitford: Yo Semites!!! QAnon doesn...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>1.602825e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri Oct 16 05:01:51 +0000 2020</td>\n",
       "      <td>1316967569794977792</td>\n",
       "      <td>1316967569794977792</td>\n",
       "      <td>RT @ACTBrigitte: Retweet if President Trump wo...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>1.602825e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at                   id               id_str  \\\n",
       "0  Fri Oct 16 05:01:51 +0000 2020  1316967569660776450  1316967569660776450   \n",
       "1  Fri Oct 16 05:01:51 +0000 2020  1316967569648222211  1316967569648222211   \n",
       "2  Fri Oct 16 05:01:51 +0000 2020  1316967569652371456  1316967569652371456   \n",
       "3  Fri Oct 16 05:01:51 +0000 2020  1316967569652371458  1316967569652371458   \n",
       "4  Fri Oct 16 05:01:51 +0000 2020  1316967569794977792  1316967569794977792   \n",
       "\n",
       "                                                text  \\\n",
       "0  RT @RudyGiuliani: The competing Town Halls wer...   \n",
       "1  RT @rachelv12: Trump and machismo  https://t.c...   \n",
       "2  RT @briantylercohen: Biden is like an encyclop...   \n",
       "3  RT @BradleyWhitford: Yo Semites!!! QAnon doesn...   \n",
       "4  RT @ACTBrigitte: Retweet if President Trump wo...   \n",
       "\n",
       "                                              source truncated  \\\n",
       "0  <a href=\"https://mobile.twitter.com\" rel=\"nofo...     False   \n",
       "1  <a href=\"https://mobile.twitter.com\" rel=\"nofo...     False   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...     False   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...     False   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...     False   \n",
       "\n",
       "   in_reply_to_status_id  in_reply_to_status_id_str in_reply_to_user_id  \\\n",
       "0                    NaN                        NaN                 NaN   \n",
       "1                    NaN                        NaN                 NaN   \n",
       "2                    NaN                        NaN                 NaN   \n",
       "3                    NaN                        NaN                 NaN   \n",
       "4                    NaN                        NaN                 NaN   \n",
       "\n",
       "   in_reply_to_user_id_str  ... quote_count reply_count retweet_count  \\\n",
       "0                      NaN  ...         0.0           0             0   \n",
       "1                      NaN  ...         0.0           0             0   \n",
       "2                      NaN  ...         0.0           0             0   \n",
       "3                      NaN  ...         0.0           0             0   \n",
       "4                      NaN  ...         0.0           0             0   \n",
       "\n",
       "  favorite_count                                           entities  \\\n",
       "0              0  {'hashtags': [], 'urls': [], 'user_mentions': ...   \n",
       "1              0  {'hashtags': [], 'urls': [{'url': 'https://t.c...   \n",
       "2              0  {'hashtags': [], 'urls': [], 'user_mentions': ...   \n",
       "3              0  {'hashtags': [], 'urls': [], 'user_mentions': ...   \n",
       "4              0  {'hashtags': [], 'urls': [], 'user_mentions': ...   \n",
       "\n",
       "   favorited retweeted  filter_level lang  timestamp_ms  \n",
       "0      False     False           low   en  1.602825e+12  \n",
       "1      False     False           low   en  1.602825e+12  \n",
       "2      False     False           low   en  1.602825e+12  \n",
       "3      False     False           low   en  1.602825e+12  \n",
       "4      False     False           low   en  1.602825e+12  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('all_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
